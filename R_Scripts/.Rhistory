}, error = function(e) {
warning("GO term mapping failed: ", e$message)
data.frame(GOID = all_go_ids, Term = all_go_ids)
})
# 7. Document-topic probabilities
doc_topics <- tidy(lda_model, matrix = "gamma")
# 8. Create network components
topic_docs <- doc_topics %>%
group_by(topic) %>%
slice_max(gamma, n = n_topDocs) %>%
ungroup()
topic_terms <- top_terms %>%
group_by(topic) %>%
slice_max(beta, n = n_topTerms) %>%
ungroup()
# Create edges
dt_edges <- topic_docs %>%
inner_join(topic_terms, by = "topic") %>%
transmute(
from = document,
to = term,
topic = topic,
weight = gamma,
type = "doc-term"
)
# Create nodes
nodes <- data.frame(
name = unique(c(dt_edges$from, dt_edges$to)),
stringsAsFactors = FALSE
) %>%
mutate(
type = ifelse(name %in% dt_edges$from, "document", "term"),
topic = ifelse(
type == "document",
doc_topics$topic[match(name, doc_topics$document)],
topic_terms$topic[match(name, topic_terms$term)]
),
color = case_when(
type == "document" & name %in% abs_ratio$Gene ~ abs_ratio$color[match(name, abs_ratio$Gene)],
type == "term" ~ viridis(k)[topic],
TRUE ~ "gray80"
),
label = ifelse(
type == "term",
go_terms$Term[match(gsub("go", "GO:", name), go_terms$GOID)],
name
)
)
# Create graph
doc_term_graph <- tbl_graph(
nodes = nodes,
edges = dt_edges,
directed = TRUE
)
# Plot graph
sgraph <- ggraph(doc_term_graph, layout = graph_layout) +
geom_edge_link(
aes(alpha = 0.5),#as.character(topic), alpha = weight),
color = "grey",
width = 0.5
) +
geom_node_point(
aes(color = color, size = ifelse(type == "term", 4, 2),
alpha = 1.0)
) +
geom_node_text(
aes(label = label, filter = type == "document"),
repel = TRUE,
size = 1
) +
geom_node_text(
aes(
label = ifelse(type == "term", label, ""),
size = ifelse(type == "term", 3, 0)  # Dynamic sizing
),
repel = TRUE,
box.padding = 0.2,
point.padding = 0.1,
size = 3,
color = "Black",
max.overlaps = 20
) +
if (hull){
geom_mark_hull(
aes(x, y, group = topic, fill = as.factor(topic)),
concavity = 1,
expand = unit(2, "mm"),
alpha = 0.05,
size = 0.2
)
} +
guides(
color = topic,
size = "none",
alpha = "none"
) +
scale_color_identity() +
# Adjust scales and theme
scale_size_continuous(range = c(2, 6)) +
coord_cartesian(clip = "off")+ # Allow labels to extend beyond plot
labs(title = "Document-Term Network")
return(list(
simPlot = sgraph,
topTermPlot = top_term_plot,
topTerms = top_terms,
goTerms = go_terms
))
}
library(plotly)
function_df <- read.csv("../Data/Function_Descriptions.csv", row.names = 1)
# Check the exact gene name in UniProt first
function_descriptions <- function_df$GO
corpus <- Corpus(VectorSource(function_descriptions)) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, paste0("\\b", stopwords("en"), "\\b")) %>%
tm_map(stemDocument)
function_df$Functions <- sapply(corpus, as.character)
#function_df <- na.omit(function_df)
#function_df <- subset(function_df, select = - function_term)
Master_df <- inner_join(function_df, heatmap_data, by = "Gene")
Master_df$GO_corpus <- sapply(corpus, as.character)
Master_df <- na.omit(Master_df)
Master_df$identity <- paste(Master_df$Gene, Master_df$genotype)
plots <- list()
for (k in c(3, 4, 5, 6, 7, 8, 9, 10, 11)){
results  <- LDA_SSM(Master_df,
GO_corpus = Master_df$GO_corpus,
k = k,
n_topTerms = 3,
p_sparse = 0.94,
n_topTopics = k,
n_topDocs = 50,
graph_layout = "stress",
)
plots[[k-2]] <- results$simPlot
}
library(patchwork)
combined_plot <- wrap_plots(plots, ncol = 3) +
plot_annotation(title = "Comparison of Gene Sorting Methods") &
theme(plot.margin = margin(1,1,1,1, "cm"))
ggsave("../Figures/combined_sim_graphs.png",
combined_plot,
width = 24,
height = 20,
dpi=300,
limits = FALSE)
LDA_SSM <- function(Master_df,
GO_corpus,
k = 3,
n_topTerms = 10,
p_sparse = 0.999,
n_topDocs = 1,
hull = FALSE,
graph_layout = "fr") {
# Load required packages quietly
suppressPackageStartupMessages({
require(tidytext)
require(topicmodels)
require(ggraph)
require(tidygraph)
require(patchwork)
require(viridis)
require(AnnotationDbi)
})
# 1. Create DTM more efficiently
dtm <- Master_df %>%
unnest_tokens(word, !!sym(GO_corpus)) %>%
count(Gene, word) %>%
cast_dtm(Gene, word, n)
# Validate DTM
if(!inherits(dtm, "DocumentTermMatrix")) {
stop("Failed to create valid DocumentTermMatrix")
}
message("Initial DTM dimensions: ", paste(dim(dtm), collapse = " x "))
# 2. Filter sparse terms and empty docs
lda_dtm <- dtm %>%
removeSparseTerms(sparse = p_sparse) %>%
.[rowSums(as.matrix(.)) > 0, ]
message("Final DTM dimensions: ", paste(dim(lda_dtm), collapse = " x "))
if(nrow(lda_dtm) == 0) stop("No documents remaining after filtering")
# 3. Run LDA with progress
message("Running LDA with k=", k, " topics...")
lda_model <- LDA(lda_dtm, k = k, control = list(seed = 123))
# 4. Extract top terms with progress bar
message("Extracting top terms...")
top_terms <- tidy(lda_model, matrix = "beta") %>%
group_by(topic) %>%
slice_max(beta, n = n_topTerms, with_ties = FALSE) %>%
ungroup() %>%
arrange(topic, -beta)
top_term_plot <- ggplot(top_terms, aes(x = reorder_within(term, beta, topic),
y = beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
labs(title = paste("Top", n_topTerms, "Terms per Topic"),
x = "Term", y = "Beta (Probability)") +
theme_minimal()
# 5. Compute log2fold ratios more efficiently
abs_ratio <- Master_df %>%
filter(genotype %in% c("s4", "NC")) %>%
group_by(Gene) %>%
filter(n() == 2) %>%
summarize(
log2fold_ratio = abs(log2FoldChange[genotype == "s4"]) /
abs(log2FoldChange[genotype == "NC"]),
color = case_when(
log2fold_ratio > 1 ~ "red",
log2fold_ratio < 1 ~ "blue",
TRUE ~ "gray"
)
)
# 6. Improved GO term mapping with caching
all_go_ids <- unique(na.omit(unlist(strsplit(Master_df$GO, ",\\s*"))))
go_terms <- tryCatch({
data.frame(
GOID = all_go_ids,
Term = AnnotationDbi::Term(all_go_ids),
stringsAsFactors = FALSE
)
}, error = function(e) {
warning("GO term mapping failed: ", e$message)
data.frame(GOID = all_go_ids, Term = all_go_ids, stringsAsFactors = FALSE)
})
# 7. Document-topic probabilities
doc_topics <- tidy(lda_model, matrix = "gamma")
# 8. Network creation optimized
create_network <- function() {
topic_docs <- doc_topics %>%
group_by(topic) %>%
slice_max(gamma, n = n_topDocs, with_ties = FALSE) %>%
ungroup()
topic_terms <- top_terms %>%
group_by(topic) %>%
slice_max(beta, n = n_topTerms, with_ties = FALSE) %>%
ungroup()
# Create edges
dt_edges <- topic_docs %>%
inner_join(topic_terms, by = "topic") %>%
transmute(
from = document,
to = term,
topic = topic,
weight = gamma,
type = "doc-term"
)
# Create nodes with memoization
nodes <- tibble(
name = unique(c(dt_edges$from, dt_edges$to))
) %>%
mutate(
type = ifelse(name %in% dt_edges$from, "document", "term"),
topic = ifelse(
type == "document",
doc_topics$topic[match(name, doc_topics$document)],
topic_terms$topic[match(name, topic_terms$term)]
),
color = case_when(
type == "document" & name %in% abs_ratio$Gene ~
abs_ratio$color[match(name, abs_ratio$Gene)],
type == "term" ~ viridis(k, option = "D")[topic],
TRUE ~ "gray80"
),
label = ifelse(
type == "term",
go_terms$Term[match(gsub("go", "GO:", name), go_terms$GOID)],
name
),
size = ifelse(type == "term", 4, 2)
)
tbl_graph(nodes = nodes, edges = dt_edges, directed = FALSE)
}
doc_term_graph <- create_network()
# 9. Optimized plotting
message("Creating network visualization...")
base_plot <- ggraph(doc_term_graph, layout = graph_layout) +
geom_edge_link(
color = "grey",
width = 0.5,
alpha = 0.5
) +
geom_node_point(
aes(color = color, size = size),
alpha = 1.0
) +
scale_size_identity() +
scale_color_identity() +
coord_cartesian(clip = "off") +
labs(title = "Document-Term Network") +
theme_graph()
# Conditional hull addition
if(hull) {
base_plot <- base_plot +
geom_mark_hull(
aes(x, y, group = topic, fill = as.factor(topic)),
concavity = 1,
expand = unit(2, "mm"),
alpha = 0.05,
size = 0.2,
show.legend = FALSE
)
}
# Add text layers last for better rendering
final_plot <- base_plot +
geom_node_text(
aes(label = ifelse(type == "document", label, ""),
size = 3),
repel = TRUE,
max.overlaps = Inf,
point.padding = 0.1,
box.padding = 0.2
) +
geom_node_text(
aes(label = ifelse(type == "term", label, ""),
size = 2),
repel = TRUE,
color = "black",
max.overlaps = 20,
point.padding = 0.05,
box.padding = 0.1
)
return(list(
simPlot = final_plot,
topTermPlot = top_term_plot,
topTerms = top_terms,
goTerms = go_terms,
ldaModel = lda_model
))
}
# Optimized plotting code
library(future)
plan(multisession)  # Enable parallel processing
# Preprocess data more efficiently
preprocess_data <- function() {
function_df <- read.csv("../Data/Function_Descriptions.csv",
stringsAsFactors = FALSE)
heatmap_data <- read.csv("../Data/Heatmap_Data.csv",
stringsAsFactors = FALSE)
corpus <- tm::Corpus(tm::VectorSource(function_df$GO)) %>%
tm::tm_map(tm::removePunctuation) %>%
tm::tm_map(tm::removeWords, tm::stopwords("en")) %>%
tm::tm_map(tm::stemDocument)
function_df$GO_corpus <- sapply(corpus, as.character)
Master_df <- merge(function_df, heatmap_data, by = "Gene", all = FALSE) %>%
na.omit() %>%
mutate(identity = paste(Gene, genotype))
return(Master_df)
}
Master_df <- preprocess_data()
# Parallelized plot generation
generate_plots <- function(k_values) {
furrr::future_map(k_values, function(k) {
results <- LDA_SSM(
Master_df,
GO_corpus = "GO_corpus",
k = k,
n_topTerms = 3,
p_sparse = 0.94,
n_topDocs = 50,
graph_layout = "stress"
)
results$simPlot
}, .options = furrr::furrr_options(seed = TRUE))
}
k_values <- 3:11
plots <- generate_plots(k_values)
# Save combined plot with proper dimensions
combined_plot <- wrap_plots(plots, ncol = 3, guides = "collect") +
plot_annotation(title = "Comparison of Gene Sorting Methods") &
theme(plot.margin = margin(1, 1, 1, 1, "cm"))
ggsave(
"../Figures/combined_sim_graphs.png",
combined_plot,
width = 24,
height = 20,
dpi = 300,
limitsize = FALSE
)
write.csv(Master_df, file = "../Data/Master_df.csv", row.names = FALSE)
Master_df$identity <- paste(Master_df$Gene, Master_df$genotype)
Master_df
source("optimized_lda.R")
# Initialize analyzer with validation
analyzer <- OptimizedLDAAnalyzer$new(
master_df = Master_df,
go_corpus_col = "GO"  # Column containing GO terms
)
# Debug
analyzer$validate()
analyzer$master_df
analyzer$go_corpus_col
analyzer$get_valid_go()
analyzer$prepare_dtm()
analyzer$find_optimal_k()
analyzer$fit_lda()
analyzer$build_genotype_network()
analyzer$build_topic_document_network()
analyzer$plot_topic_document_graph()
analyzer$plot_topic_network()
# Debug
analyzer$validate()
analyzer$master_df
analyzer$go_corpus_col
analyzer$get_valid_go()
analyzer$prepare_dtm()
analyzer$find_optimal_k()
analyzer$fit_lda()
analyzer$build_genotype_network()
analyzer$build_term_network()
# Debug
analyzer$validate()
analyzer$master_df
analyzer$go_corpus_col
analyzer$get_valid_go()
analyzer$prepare_dtm()
analyzer$find_optimal_k()
analyzer$fit_lda()
analyzer$build_genotype_network()
analyzer$build_topic_network()
analyzer$build_topic_document_network()
analyzer$plot_topic_document_graph()
analyzer$plot_topic_network()
source("optimized_lda.R")
# Initialize analyzer with validation
analyzer <- OptimizedLDAAnalyzer$new(
master_df = Master_df,
go_corpus_col = "GO"  # Column containing GO terms
)
# Debug
analyzer$validate()
analyzer$master_df
analyzer$go_corpus_col
analyzer$get_valid_go()
analyzer$prepare_dtm()
analyzer$find_optimal_k()
analyzer$fit_lda()
analyzer$build_genotype_network()
analyzer$build_topic_network()
analyzer$build_topic_document_network()
analyzer$plot_topic_document_graph()
analyzer$plot_topic_network()
source("optimized_lda.R")
# Initialize analyzer with validation
analyzer <- OptimizedLDAAnalyzer$new(
master_df = Master_df,
go_corpus_col = "GO"  # Column containing GO terms
)
source("optimized_lda.R")
# Initialize analyzer with validation
analyzer <- OptimizedLDAAnalyzer$new(
master_df = Master_df,
go_corpus_col = "GO"  # Column containing GO terms
)
# Debug
analyzer$validate()
analyzer$master_df
analyzer$go_corpus_col
analyzer$get_valid_go()
analyzer$prepare_dtm()
analyzer$find_optimal_k()
analyzer$fit_lda()
analyzer$build_genotype_network()
analyzer$build_topic_network()
analyzer$build_topic_document_network()
analyzer$plot_topic_document_graph()
analyzer$plot_topic_network()
source("optimized_lda.R")
# Initialize analyzer with validation
analyzer <- OptimizedLDAAnalyzer$new(
master_df = Master_df,
go_corpus_col = "GO"  # Column containing GO terms
)
# Debug
analyzer$validate()
analyzer$master_df
analyzer$go_corpus_col
analyzer$get_valid_go()
analyzer$prepare_dtm()
analyzer$find_optimal_k()
analyzer$fit_lda()
analyzer$build_genotype_network()
analyzer$build_topic_network()
analyzer$build_topic_document_network()
analyzer$plot_topic_document_graph()
analyzer$plot_topic_network()
dtm <- analyzer$dtm
k <- analyzer$optimal_k
lda_model <- analyzer$lda_model
top_doc_network <- analyzer$build_topic_document_network(gamma_threshold = 0.1)
topic_network <- analyzer$build_topic_network()
doc_doc_network <- analyzer$build_document_network()
combined_network <- analyzer$combine_networks()
multiplex_network <- analyzer$plot_multiplex_network()
combined_network_tbl <- as_tibble(combined_network)
top_doc_network
View(top_doc_network)
dtm <- analyzer$dtm
k <- analyzer$optimal_k
lda_model <- analyzer$lda_model
top_doc_network <- analyzer$build_topic_document_network(gamma_threshold = 0.1)
topic_network <- analyzer$build_topic_network()
top_doc_tibble <- as_tibble(top_doc_network)
doc_doc_network <- analyzer$build_document_network()
combined_network <- analyzer$combine_networks()
multiplex_network <- analyzer$plot_multiplex_network()
combined_network_tbl <- as_tibble(combined_network)
View(top_doc_tibble)
View(top_doc_network)
top_doc_tibble <- as_tibble(top_doc_network$edges)
View(top_doc_tibble)
View(top_doc_tibble)
